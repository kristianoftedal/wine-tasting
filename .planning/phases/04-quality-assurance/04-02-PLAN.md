---
phase: 04-quality-assurance
plan: 02
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - src/lib/similarity.test.ts
  - scripts/recalculate-scores.ts
autonomous: true

must_haves:
  truths:
    - "Localhost detection correctly identifies local vs server environment"
    - "Semantic similarity switches between local and OpenAI based on environment"
    - "API exports (lemmatizeAndWeight, analyze, getCategoryWeight) have stable signatures"
    - "Migration script can recalculate scores with new profiles"
  artifacts:
    - path: "src/lib/similarity.test.ts"
      provides: "Integration tests for similarity switching"
      min_lines: 40
    - path: "scripts/recalculate-scores.ts"
      provides: "Score recalculation migration script"
      min_lines: 30
  key_links:
    - from: "src/lib/similarity.test.ts"
      to: "isLocalhost logic"
      via: "environment variable testing"
      pattern: "VERCEL_URL|NEXT_PUBLIC_VERCEL_URL"
    - from: "scripts/recalculate-scores.ts"
      to: "src/lib/lemmatizeAndWeight.ts"
      via: "import lemmatizeAndWeight"
      pattern: "import.*lemmatizeAndWeight"
---

<objective>
Test localhost/server environment switching and provide migration script for score recalculation.

Purpose: Verify QUAL-01 through QUAL-04 requirements are met - both environments work correctly and existing API signatures are unchanged.

Output: Integration tests for similarity switching, API compatibility verification, and migration script for recalculating scores with new weight profiles.
</objective>

<execution_context>
@/Users/kristianoftedal/.claude/get-shit-done/workflows/execute-plan.md
@/Users/kristianoftedal/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-quality-assurance/04-RESEARCH.md
@.planning/phases/04-quality-assurance/04-01-SUMMARY.md

@src/actions/wine-recommendations-sql.ts
@src/lib/localSemanticSimilarity.ts
@src/lib/semanticSimilarity.ts
@src/lib/lemmatizeAndWeight.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Write localhost/server switching tests</name>
  <files>
    src/lib/similarity.test.ts
  </files>
  <action>
    Create src/lib/similarity.test.ts testing environment-based switching logic.

    Note: The isLocalhost function is private in wine-recommendations-sql.ts. Test the behavior indirectly or test the public functions that use it.

    **Test isLocalhost behavior patterns:**
    1. Create test helper that replicates isLocalhost logic:
       ```typescript
       function testIsLocalhost(vercelUrl: string | undefined, nextPublicVercelUrl: string | undefined): boolean {
         const host = vercelUrl || nextPublicVercelUrl || '';
         return !host || host.includes('localhost') || host.includes('127.0.0.1');
       }
       ```

    2. Test localhost detection:
       - Empty VERCEL_URL and NEXT_PUBLIC_VERCEL_URL -> true (localhost)
       - VERCEL_URL='my-app.vercel.app' -> false (server)
       - VERCEL_URL='localhost:3000' -> true (localhost)
       - VERCEL_URL='127.0.0.1:3000' -> true (localhost)

    3. Test localSemanticSimilarity function directly:
       - Import localSemanticSimilarity from '@/lib/localSemanticSimilarity'
       - Test that it returns a number between 0 and 100
       - Test similar texts return higher scores than dissimilar texts
       - Example: similarity('solbær og kirsebær', 'solbær og blåbær') > similarity('solbær', 'pepper og nellik')

    4. API signature verification (compile-time):
       - Use expectTypeOf from vitest to verify:
         - lemmatizeAndWeight returns TextAnalysis
         - analyze returns AnalysisResult | undefined
         - getCategoryWeight returns number
         - localSemanticSimilarity returns Promise<number>
         - semanticSimilarity returns Promise<number>

    **Pattern for type testing:**
    ```typescript
    import { expectTypeOf } from 'vitest'
    import type { TextAnalysis, AnalysisResult } from './lemmatizeAndWeight'
    import { lemmatizeAndWeight, analyze } from './lemmatizeAndWeight'

    describe('API Compatibility', () => {
      it('lemmatizeAndWeight returns TextAnalysis', () => {
        expectTypeOf(lemmatizeAndWeight).returns.toMatchTypeOf<TextAnalysis>()
      })
    })
    ```

    DO NOT mock Xenova/OpenAI - test the logic, not the providers.
    DO NOT test semanticSimilarity with actual API calls (would require keys).
  </action>
  <verify>
    Run `npm test -- --run src/lib/similarity.test.ts`
    All tests pass.
  </verify>
  <done>
    Localhost/server switching logic tested, API signatures verified via types
  </done>
</task>

<task type="auto">
  <name>Task 2: Create score recalculation migration script</name>
  <files>
    scripts/recalculate-scores.ts
  </files>
  <action>
    Create scripts/recalculate-scores.ts for recalculating similarity scores with new weight profiles.

    **Script requirements:**
    1. Connect to Supabase using environment variables:
       - SUPABASE_URL (or NEXT_PUBLIC_SUPABASE_URL)
       - SUPABASE_SERVICE_ROLE_KEY (for write access)

    2. Fetch all wines with smell/taste notes

    3. For each wine, recalculate lemmatization with current profile:
       - Call lemmatizeAndWeight(wine.smell)
       - Call lemmatizeAndWeight(wine.taste)
       - Log the analysis for verification

    4. Dry-run by default (--execute flag for actual changes)

    5. Show summary at end:
       - Total wines processed
       - Profile used (from env)
       - Any errors encountered

    **Script structure:**
    ```typescript
    #!/usr/bin/env npx tsx
    import 'dotenv/config'
    import { createClient } from '@supabase/supabase-js'
    import { lemmatizeAndWeight, getActiveProfile } from '../src/lib/profiles'

    async function main() {
      const isDryRun = !process.argv.includes('--execute')
      const profile = getActiveProfile()

      console.log(`Using profile: ${profile.name}`)
      console.log(`Mode: ${isDryRun ? 'DRY RUN' : 'EXECUTE'}`)

      const supabase = createClient(
        process.env.SUPABASE_URL || process.env.NEXT_PUBLIC_SUPABASE_URL!,
        process.env.SUPABASE_SERVICE_ROLE_KEY!
      )

      // Fetch and process wines...
    }

    main().catch(console.error)
    ```

    6. Add script to package.json:
       ```json
       "recalculate-scores": "tsx scripts/recalculate-scores.ts"
       ```

    **Note:** This script is for manual verification/migration. It reads data and shows what would change; actual database updates are out of scope for this phase (no score column to update currently).
  </action>
  <verify>
    Run `npm run recalculate-scores` (dry run mode)
    Script executes without errors and shows wine count and profile info.
  </verify>
  <done>
    Migration script created that can recalculate scores with new profiles
  </done>
</task>

<task type="auto">
  <name>Task 3: Final verification and test suite run</name>
  <files></files>
  <action>
    Run full verification suite:

    1. Run all tests: `npm test -- --run`
       - All tests should pass
       - No flaky tests (run twice to verify)

    2. Run TypeScript build: `npm run build`
       - Should complete without errors
       - Confirms no breaking API changes

    3. Verify test coverage is sensible:
       - lemmatizeAndWeight core functions tested
       - Profile selection and fallback tested
       - Localhost detection logic tested
       - API type signatures verified

    4. Create summary of what's tested vs. what relies on manual verification:
       - Unit tests: lemmatization, profiles, similarity scoring logic
       - Type tests: API compatibility
       - Manual: actual Xenova loading, actual OpenAI calls (external dependencies)

    If any tests fail, fix them before marking complete.
  </action>
  <verify>
    `npm test -- --run` exits 0 with all tests passing
    `npm run build` exits 0
  </verify>
  <done>
    Full test suite passes, build succeeds, phase 04 requirements verified
  </done>
</task>

</tasks>

<verification>
After completing all tasks:
1. `npm test -- --run` passes all tests (unit + integration)
2. `npm run build` succeeds (API compatibility maintained)
3. `npm run recalculate-scores` runs in dry-run mode
4. Phase 04 success criteria verified:
   - QUAL-01: Localhost/server split works (tested)
   - QUAL-02: Local similarity works with Xenova (tested indirectly)
   - QUAL-03: Server similarity works with OpenAI (type-verified, manual test needed)
   - QUAL-04: No breaking API changes (TypeScript compilation + type tests)
</verification>

<success_criteria>
- Similarity switching tests cover localhost detection logic
- API signatures verified via expectTypeOf
- Migration script runs in dry-run mode
- All tests pass on `npm test -- --run`
- Build succeeds confirming no breaking changes
</success_criteria>

<output>
After completion, create `.planning/phases/04-quality-assurance/04-02-SUMMARY.md`
</output>
